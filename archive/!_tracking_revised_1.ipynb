{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc66d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_video\n",
    "from torchvision.ops import box_convert\n",
    "\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn, MaskRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4f420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_graph_path = f'../DVUChallenge/dev_dataset/scenes_knowledge_graphs/'\n",
    "\n",
    "shots_data_path = f'../DVUChallenge/dev_dataset/movie.shots/'\n",
    "\n",
    "dec_rate = 50\n",
    "\n",
    "filmnames = [file for file in listdir(f'../DVUChallenge/dev_dataset/movie_knowledge_graph/') if '.' not in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb27ecf",
   "metadata": {},
   "source": [
    "### Object-based tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074205c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch\n",
    "!git clone https://github.com/paul-pias/Face-Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfd1b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_rcnn_labels = np.array(['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dacc763",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = maskrcnn_resnet50_fpn(weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT).cuda()\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7540497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_2_mask(bbox, dims=(1,720,1280)):\n",
    "    base = np.zeros(shape=(1,720,1280))\n",
    "    base[0, bbox[1]:bbox[3],bbox[0]:bbox[2]] = 1\n",
    "    return base\n",
    "\n",
    "# ================\n",
    "\n",
    "def getLastCentersForAllEntities(entityList):\n",
    "    centers = []\n",
    "    for entity in entityList:\n",
    "        centers.append(entity['centers'][-1])\n",
    "    return centers\n",
    "\n",
    "def getClosestEntity(center, entityCenters):\n",
    "    dists = []\n",
    "    for entity_center in entityCenters:\n",
    "        dists.append(distance.euclidean(center.cpu(), entity_center.cpu()))\n",
    "    \n",
    "    print('Distances - ', dists)\n",
    "    if len(dists) == 0:\n",
    "        return None\n",
    "    result = np.argmin(dists)\n",
    "    if dists[result] > 100:  \n",
    "        return None\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "def getCenter(box):\n",
    "    return box_convert(box, in_fmt = 'xyxy', out_fmt = 'cxcywh')[:2]\n",
    "\n",
    "def overlapFaceIndex(mask, faceBoxes):\n",
    "\n",
    "    mask_b = (mask > 0.01).int().cpu()\n",
    "    int_rates = []\n",
    "    \n",
    "    for i, faceBox in enumerate(faceBoxes):\n",
    "        base = np.zeros(shape=mask_b.shape)\n",
    "        base[0, faceBox[1]:faceBox[3],faceBox[0]:faceBox[2]] = 1\n",
    "\n",
    "        A,B = mask_b, torch.Tensor(base)\n",
    "\n",
    "        int_rates.append([i, torch.where((A == B) & (B == 1), 1, 0).int().sum()/B.sum()])\n",
    "        \n",
    "    int_rates.sort(key=lambda x: x[1])\n",
    "    int_rates = int_rates[::-1]\n",
    "    \n",
    "    if len(int_rates) == 0:\n",
    "        return None\n",
    "    \n",
    "    if int_rates[0][1] > 0.5:\n",
    "        return int_rates[0][0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33aa49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_entity_list(frameID, entityList, boxes, masks):\n",
    "    boundingBoxes, maskList = boxes[frameID], masks[frameID]\n",
    "    print('Person bounding boxes - ', boundingBoxes)\n",
    "    \n",
    "    nameList, faceBoxes = face_rec_res[frameID]\n",
    "    print('Name list - ', nameList, 'Face boxes - ', faceBoxes)                                   \n",
    "    \n",
    "    entityCenters = getLastCentersForAllEntities(entityList)\n",
    "    \n",
    "    for box, mask in zip(boundingBoxes, maskList):\n",
    "        print('   The current bbox is - ', box)\n",
    "        center = getCenter(box.detach())\n",
    "        \n",
    "        if overlapFaceIndex(mask, faceBoxes) != None:\n",
    "            correctName = nameList[overlapFaceIndex(mask, faceBoxes)]\n",
    "        else:\n",
    "            correctName = None\n",
    "            \n",
    "        print('   Face Index - ', overlapFaceIndex(mask, faceBoxes), ' with corresp. name ', correctName)\n",
    "        \n",
    "        print('   Bbox center is: ',center, '; Last entity centers are: ', entityCenters)\n",
    "        correctEntity = getClosestEntity(center, entityCenters)\n",
    "        print('   Closest entity index is ', correctEntity)\n",
    "        \n",
    "        if correctEntity is None:\n",
    "            newEntity = {'centers':[], 'boxes':[], 'frameID':[], 'names':[]} # createNewEntity()\n",
    "            newEntity['boxes'].append(box.detach())\n",
    "            newEntity['centers'].append(center) # newEntity.addLastCenter(center, frameID)\n",
    "            newEntity['frameID'].append(frameID) # ...\n",
    "            \n",
    "            if correctName is not None:\n",
    "                newEntity['names'].append(correctName) # newEntity.addName(correctName)\n",
    "            \n",
    "            print('   Creating new entity - ', newEntity)\n",
    "            \n",
    "            entityList.append(newEntity)\n",
    "        else:\n",
    "            \n",
    "            print('   Adding data to existing entity.')\n",
    "            \n",
    "            entityList[correctEntity]['boxes'].append(box.detach())\n",
    "            entityList[correctEntity]['centers'].append(center) # correctEntity.addLastCenter(center, frameID)\n",
    "            entityList[correctEntity]['frameID'].append(frameID)\n",
    "            \n",
    "            if correctName is not None:\n",
    "                entityList[correctEntity]['names'].append(correctName) # correctEntity.addName(correctName)\n",
    "    \n",
    "    return entityList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75795233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbfde2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d32199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32bf0760",
   "metadata": {},
   "source": [
    "### Pose-based tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cccefa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f939a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
